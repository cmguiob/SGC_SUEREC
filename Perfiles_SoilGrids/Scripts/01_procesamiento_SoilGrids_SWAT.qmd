---
title: "Generación de BD suelos desde SoilGrids"
author: Carlos Guío
format: html
---

Este cuaderno permite crear una base de datos de suelos para SWAT a partir de la base datos de suelos globales de SoilGrids. Se siguen los siguietes pasos:

1. Descarga de los polígonos de área de estudio y unidades cartográficas (si las hay)
2. Descarga de programática de datos de SoilGrids para propiedades, resolución y profundidades elegidas.
3. Cálculo de perfiles promedio por unidad cartográfica
4. Cálculo de perfiles modales a partir de la variabilidad de datos en el área de estudio
5. Generación de datos en formato SWAT


```{r setup}

# Para cargar librerias se verifica pacman
if ("pacman" %in% installed.packages() == FALSE) install.packages("pacman")

# Se cargan las librerias
pacman::p_load(char = c(
  "here", #manejo de rutas
  "sf", #manipulación de dats espaciales
  "dplyr", #procesamiento de data frames
  "tidyr", #procesamient ode data frames
  "aqp", #datos de suelos
  "pbapply" #barra de progreso
  "ggplot2",  #graficación
  "patchwork", #mosaicos gráficos
  "wesanderson", #paleta de colores
  "qs" #escribir y leer rápidamente objetos R
  )
)

#Paleta de colores
pal <- wes_palette("Zissou1", 100, type = "continuous")

# Ajusta tamaño de letra para las gráficas que genere el script
theme(base_size = 14)

```


## 1. Carga y homogeneización de datos de polígonos

Los datos de polígonos se requieren para acotar el área de estudio (`poli_estudio`) y pára estimar propiedades dentro de unidades cartográficas (UCS) previamente definidas por el IGAC (`poli_ucs`). Se debe seleccionar el mapa de UCS con la escala mas detallada.

```{r}

#Descarga mapa de ucs armonizadas para Colombia, escala 1:100k desde Zenodo
source(here("Perfiles_SoilGrids", "Scripts", "00_funcion_descarga_ucs_armonizadas_gpkg.R"), encoding = "UTF-8")

#ucs_sf se crea automáticamente al correr la función. Selecciona columnas y filas relevantes
poli_ucs <- ucs_sf  |>
  dplyr::select(UCSuelo, SUBGRUPO, PERFILES, PORCENTAJE, AREA_HA) |>
  sf::st_make_valid()

# Descarga polígono de área de estudio
poli_estudio <- st_read(here("Perfiles_SoilGrids", "Data", "poligono_tocaima.geojson"))

# Transformar ambos al CRS nativo de SoilGrids (IGH: EPSG:54052)
wkt_igh <- '+proj=igh +lat_0=0 +lon_0=0 +datum=WGS84 +units=m +no_defs'
poli_ucs_igh <- st_transform(poli_ucs, wkt_igh)
poli_estudio_igh <- st_transform(poli_estudio, st_crs(poli_ucs_igh))


# Clip
estudio_ucs_clip <- st_intersection(poli_ucs_igh, poli_estudio_igh)
estudio_ucs_clip <- estudio_ucs_clip[!st_is_empty(estudio_ucs_clip), ]

#Verifica visualmente
plot(estudio_ucs_clip)

```

## 2. Carga y validación de datos SoilGrids

Descarga datos SoilGrids (la función entrega un SpatRaster en IGH). Esto se realiza llamando a una función externa `00_funcion_descarga_soilgrids.R`, que debe estar dentro del mismo directorio de trabajo actual. Verificar con `getwd()`.

```{r}

# La descripción de los argumentos se encuentra en el script de la función
source("00_funcion_descarga_soilgrids.R")

# Se descargan los archivos si no se encuentrar en la carpeta
stack_suelo <- descargar_soilgrids_stack(
  vars = c("sand", "silt", "clay", "soc", "bdod"),
  depths = c("0-5cm", "5-15cm", "15-30cm", "30-60cm", "60-100cm"),
  stats = c("mean"),
  resolucion = c(250, 250),
  ruta_vrt = here::here("Perfiles_SoilGrids", "Data", "SoilGrids_vrt") #para guardar los archivos
)

```


## 2. Carga de datos de SoilGrids

Se cargan los datos de valores promedio para varias propiedades. Los valores promedio es una de las estadístics reportadas en SoilGrids. Otras opciones son algunos quantiles o la incertidumbre. 

Las propiedades así como los intervalos de profundidad que se eligen deben ser coherentes con el propósito del modelo y la información previa. Si en los polígonos de UCS se reportan oxisoles (sufijo *'oxs'*), ultisoles (sufijo *'ults'*), alfisoles (sufijo *'alfs'*) o andisoles (sufijo *'ands'*), deben considerarse las profundidades máximas. Si se presentan solo entisoles (sufijo *'ents'*) e inceptisoles (sufijo *'epts'*) puede trabajarse con profundidades máximas de 30 a 60 cm (verificar en la memoria de suelos). 

```{r carga}

# Crea un objeto tipo función al ejecutar un  script externo
source("00_funcion_descarga_soilgrids.R")

# Se llama la función con los argumentos adaptados al proyecto
stack_suelo_medias <- descargar_soilgrids_stack(
  vars = c("sand", "silt", "clay", "soc"),
  depths = c("0-5cm", "5-15cm", "15-30cm", "60-100cm", "100-200cm"),
  stats = c("mean"),
  resolucion = c(250, 250)
)

```

Se valida que los archivos se cargaron correctamente. 

```{r}

# Validación rápida: nombres y visual
print(names(stack_suelo))

# Selecciona algunas capas por número de índice
stack_sub <- stack_suelo[[c(1, 8, 15, 22)]]

# Grafica solo esas capas (en un mismo panel multi-cuadro)
plot(stack_sub)

```


## 3. Extracción de BD SWAT

A continuació se generan las tablas insumo para la base de datos de suelos de SWAT. Las columnas requeridas son:

* soil_id (ID por polígono de UCS)

* top (cm)

* bottom (cm)

* sand (%)

* silt (%)

* clay (%)

* soc (g/kg o % según el modelo, revisa unidad esperada)

Otras como 

* bulk density (g/cm³)

* pH

Para esto se presentan dos métodos. El método basado en estadística zonal se sugiere principalmente cuando se usen como referencia mapas de suelos a escalas detalladas y semidetalladas (> 1:50.000), en los que predominan las consociaciones o asociaciones de fácil diferenciación. Para las escalas más generales, se sugiere contrastar el resultado de la estadística zonal con el -segundo- método de propiedades por agrupamiento no supervisado.

### 3.1 Propiedades por estadística zonal 


Con este método se calculan perfiles promedio por polígono. La tabla resultante debe procesarse posteriormente para ajustarse al formato de SWAT.

```{r}

# Transformar UCs a SpatVector
estudio_ucs_vect <- vect(estudio_ucs_clip)

#Calculo de estadistica media por polígono y capa con reporte de avance
tabla_zonal <- pbapply::pblapply(
  seq_len(nrow(estudio_ucs_vect)),
  function(i) {
    terra::extract(stack_suelo, estudio_ucs_vect[i, ], fun = mean, na.rm = TRUE)
  }
)

# Une resultados
tabla_zonal <- do.call(rbind, tabla_zonal)

# Extraer estadística media por polígono y capa
#tabla_zonal <- terra::extract(stack_suelo, estudio_ucs_vect, fun = mean, na.rm = TRUE)

# tabla_zonal: una fila por polígono, columnas = capas + ID
head(tabla_zonal)


```

Se transforma la tabla zonal a formato largo. Se crean columnas de acuerdo a los nombres de las capas raster del stack. Por ejemplo el nombre de capa `sand_0-5cm_mean`, permite crear nuevas columnas y llenarlas: `property` (*sand*), `top` (*0*), `base` (*5*), `stat` (*mean*).

```{r}

# 1. Crea soil_id único (con sufijo, si hay duplicados)
tabla_zonal_id <- tabla_zonal %>%
  mutate(soil_id = make.unique(soil_id))

# 2. Pivot a formato largo (excluyendo ID y usando solo soil_id único)
tabla_long <- tabla_zonal %>%
  pivot_longer(
    cols = -c(ID, soil_id),  # Deja fuera ID y soil_id (solo pivot propiedades)
    names_to = c("property", "depth", "stat"),
    names_pattern = "([a-z]+)_([0-9]+-[0-9]+)cm_(mean|Q0.5|Q0.05|Q0.95|uncertainty)"
  ) %>%
  mutate(
    top = as.numeric(sub("([0-9]+)-([0-9]+)", "\\1", depth)),
    bottom = as.numeric(sub("([0-9]+)-([0-9]+)", "\\2", depth))
  ) %>%
  select(soil_id, property, stat, value, top, bottom)

```



