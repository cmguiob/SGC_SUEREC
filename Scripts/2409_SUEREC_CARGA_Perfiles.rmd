---
title: "Análisis de agrupamiento hidropedológico de suelos"
output: github_document
---

```{r config, include=FALSE}

# Renderiza el código 
knitr::opts_chunk$set(echo = TRUE)

# Carga de librerías
if (!require("pacman")) install.packages("pacman")

pacman::p_load(char = c("tidyverse"))

```

## Carga de datos

Los datos se estructuraron de forma mínima para permitir la lectura en R: se eliminaron encabezados de doble fila, se cambiaron nombres de columnas para eliminar espacios y caracteres especiales y se llenaron los espacios vacíos en la columna que identifica los perfiles.

```{r carga_tablas}
#Definir URL
data_url <- "https://raw.githubusercontent.com/cmguiob/SGC_SUEREC/main/Datos/IGAC_2014_PERFILES_QUINDIO_25K.csv"

#Cargar url
data <- read_csv(data_url)

# Ver datos
View(data)
```


También se cargan los datos espaciales en formato geojson que contienen las unidades cartográficas de suelos.

```{r carga_UCS}

#Se define URL que contiene los datos
geodata_URL <- "https://raw.githubusercontent.com/cmguiob/SGC_SUEREC/main/Datos/IGAC_UCS_QUINDIO_WGS84.geojson"

# Se cargan los datos
geodata <- sf::read_sf(geodata_URL, crs = "+proj=longlat +datum=WGS84 +no_defs +type=crs")

# Se visualizan los datos
View(geodata)

#Chequeo de crs
sf::st_crs(geodata)

#Chequeo espacial
plot(geodata |> filter(UCS == "CBe2"))

```

## Procesamiento de datos

Se reestructuran los datos para que puedan analizarse posteriormente. Se seleccionan columnas con informaicón relevante, se filtran filas con información incompleta, se generan columnas para la base y el tope de los horizontes y se crea un identificador para los horizontes.


```{r vars}

data_vars <- data |>
  dplyr::select(PERFIL, PROFUNDIDAD_cm, ARENA_porc, ARENA_perc_2, LIMO_porc, LIMO_perc_2, ARCILLA_porc, ARCILLA_perc_2, pH, CO_porc, Fe_ppm, DENS_real_gcm3, DENS_ap_gcm3, MACROPORO_perc, MICROPORO_perc, POROSIDAD_TOT_perc, pF_0, pF_33, pF_100, pF_500, pF_1500) |>
  tidyr::separate(col = PROFUNDIDAD_cm, into = c("TOPE", "BASE"), sep = "-") |>
  dplyr::mutate(HORIZ_ID = row_number(), .by = PERFIL) |>
  dplyr::select(PERFIL, HORIZ_ID, TOPE, BASE, everything()) |>
  tidyr::drop_na() |>
  dplyr::mutate(BASE = as.numeric(na_if(BASE, "N"))) |>
  dplyr::mutate(TOPE = as.numeric(TOPE))


View(data_vars)
```

Se consolida un conjunto de datos geoespaciales que diferencia los perfiles y componentes de las UCS. 

```{r}

geodata_perfiles <- geodata |>
  sf::st_drop_geometry() |> #se quita la geometría para evitar filas repetidas
  dplyr::select(UCS, PERFIL) |> #seleccionan variables útiles
  tidyr::separate_longer_delim(PERFIL, ",") |> #desagrega la columna de perfiles y expande el df a lo largo
  dplyr::distinct() |>
  dplyr::group_by(UCS) |> #agrupa por UCS
  dplyr::mutate(UCS_comps = paste(UCS, row_number(),  sep = "-")) |> #crea columna identificadora por perfiles
  dplyr::ungroup()

geodata_componentes <- geodata |>
  sf::st_drop_geometry() |> #se quita la geometría para evitar filas repetidas
  dplyr::select(UNIDAD_CAR, UCS, COMPONENTE) |>
  dplyr::mutate(COMPONENTE = stringr::str_trim(COMPONENTE)) |> #elimina espacios en blanco
  dplyr::mutate(COMPONENTE = stringr::str_remove(COMPONENTE, pattern = ".$")) |> #elimina puntos al final del texto
  tidyr::separate_longer_delim(COMPONENTE, ".") |> #desagrega la columna de componentes y expande el df a lo largo
  dplyr::distinct() |>
  dplyr::group_by(UCS) |> #agrupa por UCS
  dplyr::mutate(UCS_comps = paste(UCS, row_number(),  sep = "-")) |> #crea columna identificadora por componentes
  dplyr::ungroup() |>
  dplyr::mutate(ORDEN = stringr::str_extract(COMPONENTE, pattern = "^.*?(?=(neo|ents|epts|els|ids|ists|ands|olls|erts|alfs|oxs|ods|ults))(neo|ents|epts|els|ids|ists|ands|olls|erts|alfs|oxs|ods|ults)")) |>  #se extraen los nombres de los ordenes
  dplyr::filter(stringr::str_detect(ORDEN, pattern =  "neo|ents|epts|els|ids|ists|ands|olls|erts|alfs|oxs|ods|ults"))

geodata_vars <- inner_join(geodata_componentes, geodata_perfiles, by = c("UCS", "UCS_comps")) |>
  dplyr::select(UNIDAD_CAR, UCS, UCS_comps, ORDEN, PERFIL, everything()) |>
  dplyr::arrange(UCS, UCS_comps)


View(geodata_vars)
```


A continuación se hace un diagnóstico de cuantos perfiles de suelos aparecen en los datos analíticos, en los datos geoespaciales de UCS y cuantos en común.

```{r}

# Se crean objetos con el número de perfiles para los diferentes casos
n_perfiles_geodata <- geodata_vars |> select(PERFIL) |> distinct() |> count()
n_perfiles_data <- data_vars |> select(PERFIL) |> distinct() |> count()
n_perfiles_comunes <- inner_join(geodata_vars, data_vars, by = "PERFIL") |> select(PERFIL) |> distinct() |> count()

#Se crea reporte
glue::glue("Hay {n_perfiles_data} perfiles en los datos analíticos, {n_perfiles_geodata} perfiles en los datos geoespaciales de UCS y {n_perfiles_comunes} en común")

```

Se consolidan los datos analíticos y los datos geoespaciales. Se hace una fusión completa (full join) para indicar cuáles datos necesitan recuperarse de la memoria técnica.

```{r}

data_modelado_incompletos <- geodata_vars |>
  dplyr::select(UNIDAD_CAR, ORDEN, PERFIL) |>
  dplyr::distinct() |>
  full_join(data_vars, by = "PERFIL")

View(data_modelado_incompletos)

```

Se completan los ordenes con datos de la memoria técnica para aumentar el número de perfiles que se puedan modelar.

```{r}

data_modelado <- data_modelado_incompletos |>
  dplyr::mutate(ORDEN = case_when(
    PERFIL == "QS-5" ~ "Fluvaquentic Endoaquepts",
    PERFIL == "QS-7" ~ "Fluventic Humudepts",
    PERFIL == "QS-15" ~ "Fluvaquentic Humaquepts",
    PERFIL == "QS-16" ~ "Typic Dystrudepts",
    PERFIL == "QS-22" ~ "Typic Hapludands",
    PERFIL == "QS-33" ~ "Typic Endoaquepts",
    PERFIL == "QS-35" ~ "Fluvaquentic Endoaquepts",
    PERFIL == "QS-42" ~ "Typic Hapludands",
    PERFIL == "QS-46" ~ "Typic Hapludolls",
    PERFIL == "QS-48" ~ "Typic Hapludands",
    PERFIL == "QS-50" ~ "Acrudoxic Hapludands",
    PERFIL == "QS-60" ~ "Pachic Hapludands",
    PERFIL == "QS-64" ~ "Typic Hapludands",
    PERFIL == "QS-71" ~ "Aeric Endoaquepts",
    PERFIL == "QS-81" ~ "Typic Hapludands",
    PERFIL == "QS-92" ~ "Pachic Hapludands",
    TRUE ~ ORDEN
  )) |>
  tidyr::drop_na(ORDEN)

View(data_modelado)

```



A continuación se resumen algunas características de los perfiles.

```{r resumen}

# Número de perfiles
perfiles_n <- data_vars |>
  select(PERFIL) |>
  distinct() |>
  count()

# Máxima profundidad por perfil
perfil_pmax <- data_vars |>
  group_by(PERFIL) |>
  summarise(perfil_prof_max = as.numeric(max(BASE, na.rm = TRUE))) |>
  ungroup()

# Número de horizontes por perfil
perfil_nhoriz <- data_vars |>
  group_by(PERFIL) |>
  dplyr::summarise(horizontes = n()) |>
  ungroup()

# Resumir las propiedades para horizontes
horiz_prof_max <- perfil_nhoriz |>
  inner_join(perfil_pmax, by = "PERFIL") |>
  group_by(horizontes) |>
  dplyr::summarise(prof_max = max(perfil_prof_max))

horiz_prof_min <- perfil_nhoriz |>
  inner_join(perfil_pmax, by = "PERFIL") |>
  group_by(horizontes) |>
  dplyr::summarise(prof_min = min(perfil_prof_max))

horiz_n_frec <- perfil_nhoriz |>
  group_by(horizontes) |>
  dplyr::summarise(horiz_n_frec = n())

horiz_resumen <- horiz_prof_min |>
  inner_join(horiz_prof_max, by = "horizontes") |>
  inner_join(horiz_n_frec, by = "horizontes") |>
  mutate(prof_rango = paste0(prof_min," - ", prof_max, " cm")) 



# Grafica
ggplot(data = perfil_nhoriz) +
  geom_histogram(aes(x = horizontes), binwidth = 1) +
  labs(x = "Número de horizontes por perfil", y = "Frecuencia") +
  geom_label(
    label = paste0("n = ", perfiles_n),
    size = 7,
    x = 6,
    y = 20,
    label.padding = unit(1, "lines"), # Rectangle size around label
    color = "black",
    fill = "white"
  ) +
  geom_text(
    data = horiz_resumen, 
    aes(
      x = horizontes, 
      y = horiz_n_frec + 1, 
      label = paste(prof_rango)), 
      size = 3.5
  )

```


##  Modelado de perfiles con GAM t Splines

Se generan curvas suavizadas para los perfiles. Esto permite clasificar los tipos de perfiles con base en una variable numérica continua que nos representa.


```{r curvas}


```


## Clasificación no supervisada de perfiles modelo 





##
